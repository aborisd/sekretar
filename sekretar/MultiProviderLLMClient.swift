import Foundation

// MARK: - Multi-Provider LLM Client with Smart Routing
/// –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç SmartLLMRouter —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏ (RemoteLLMProvider)
/// –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–∞
@MainActor
final class MultiProviderLLMClient {

    static let shared = MultiProviderLLMClient()

    private let router: SmartLLMRouterService
    private let session: URLSession
    private let responseValidator: AIResponseValidator

    // MARK: - Configuration Keys (using RemoteLLMProvider convention)

    private enum Keys {
        // Gemini Flash
        static let geminiBaseURL = "GEMINI_BASE_URL"
        static let geminiAPIKey = "GEMINI_API_KEY"

        // OpenAI GPT-4o-mini
        static let openaiBaseURL = "OPENAI_BASE_URL"
        static let openaiAPIKey = "OPENAI_API_KEY"

        // Anthropic Claude Sonnet
        static let anthropicBaseURL = "ANTHROPIC_BASE_URL"
        static let anthropicAPIKey = "ANTHROPIC_API_KEY"

        // Fallback to generic remote config
        static let remoteBaseURL = "REMOTE_LLM_BASE_URL"
        static let remoteAPIKey = "REMOTE_LLM_API_KEY"
    }

    private init() {
        self.router = SmartLLMRouterService()
        self.responseValidator = AIResponseValidator()

        let config = URLSessionConfiguration.ephemeral
        config.timeoutIntervalForRequest = 60
        config.timeoutIntervalForResource = 90
        self.session = URLSession(configuration: config)

        // –ü–æ–¥–∫–ª—é—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫ router'—É
        router.setGenerateFunction { [weak self] model, request in
            guard let self = self else {
                throw NSError(domain: "MultiProviderClient", code: -99,
                             userInfo: [NSLocalizedDescriptionKey: "Client deallocated"])
            }
            return try await self.realGenerate(model: model, request: request)
        }

        print("üåê [MultiProviderClient] Initialized with smart routing + validation")
    }

    /// –†–µ–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è router'–∞
    private func realGenerate(model: LLMModel, request: LLMRequest) async throws -> LLMResponse {
        let startTime = Date()

        guard let (url, apiKey, modelName) = endpoint(for: model) else {
            throw NSError(domain: "MultiProviderClient", code: -1,
                         userInfo: [NSLocalizedDescriptionKey: "Model \(model.rawValue) not configured"])
        }

        let system = "You are Sekretar, a helpful planning assistant. Be concise and actionable."

        let body = ChatRequest(
            model: modelName,
            messages: [
                .init(role: "system", content: system),
                .init(role: "user", content: request.input)
            ],
            temperature: 0.6,
            max_tokens: 384,
            stream: false
        )

        let data = try await postJSON(url: url, apiKey: apiKey, body: body)
        let decoded = try JSONDecoder().decode(ChatResponse.self, from: data)

        guard let content = decoded.choices.first?.message?.content, !content.isEmpty else {
            throw NSError(domain: "MultiProviderClient", code: -2,
                         userInfo: [NSLocalizedDescriptionKey: "Empty response from \(model.rawValue)"])
        }

        let latency = Date().timeIntervalSince(startTime)

        // –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ (–¥–ª—è –º–µ—Ç—Ä–∏–∫)
        let inputTokens = request.input.split(separator: " ").count * 2
        let outputTokens = content.split(separator: " ").count * 2

        return LLMResponse(
            content: content,
            modelUsed: model,
            tokensUsed: TokenUsage(input: inputTokens, output: outputTokens),
            latencyMs: latency * 1000,
            cached: false
        )
    }

    // MARK: - Configuration Resolution

    private lazy var localPlist: [String: Any]? = {
        #if DEBUG
        for name in ["RemoteLLM.local", "RemoteLLM"] {
            if let url = Bundle.main.url(forResource: name, withExtension: "plist"),
               let data = try? Data(contentsOf: url),
               let plist = try? PropertyListSerialization.propertyList(from: data, format: nil) as? [String: Any] {
                return plist
            }
        }
        #endif
        return nil
    }()

    private func cfg(_ key: String) -> String? {
        if let s = UserDefaults.standard.string(forKey: key), !s.isEmpty { return s }
        if let s = localPlist?[key] as? String, !s.isEmpty { return s }
        if let dict = Bundle.main.infoDictionary, let s = dict[key] as? String, !s.isEmpty { return s }
        return nil
    }

    /// –ü–æ–ª—É—á–∏—Ç—å endpoint –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
    private func endpoint(for model: LLMModel) -> (URL, String?, String)? {
        switch model {
        case .geminiFlash:
            guard let base = cfg(Keys.geminiBaseURL) ?? cfg(Keys.remoteBaseURL),
                  let url = URL(string: base) else { return nil }
            return (
                url.appendingPathComponent("v1/chat/completions"),
                cfg(Keys.geminiAPIKey) ?? cfg(Keys.remoteAPIKey),
                "gemini-1.5-flash"
            )

        case .gpt4oMini:
            guard let base = cfg(Keys.openaiBaseURL) ?? cfg(Keys.remoteBaseURL),
                  let url = URL(string: base) else { return nil }
            return (
                url.appendingPathComponent("v1/chat/completions"),
                cfg(Keys.openaiAPIKey) ?? cfg(Keys.remoteAPIKey),
                "gpt-4o-mini"
            )

        case .claudeSonnet:
            guard let base = cfg(Keys.anthropicBaseURL) ?? cfg(Keys.remoteBaseURL),
                  let url = URL(string: base) else { return nil }
            return (
                url.appendingPathComponent("v1/chat/completions"),
                cfg(Keys.anthropicAPIKey) ?? cfg(Keys.remoteAPIKey),
                "claude-sonnet-4.5"
            )
        }
    }

    // MARK: - Smart Routing API

    /// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º –º–æ–¥–µ–ª–∏
    func generateWithRouting(
        _ prompt: String,
        userTier: SubscriptionTier = .free
    ) async throws -> String {

        let request = LLMRequest(input: prompt, userTier: userTier)

        // Router –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–µ—Ä–µ—Ç –º–æ–¥–µ–ª—å –∏ –∑–∞–∫—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        let response = try await router.route(request)

        return response.content
    }

    /// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –æ—Ç–≤–µ—Ç–∞ (–¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
    func generateWithValidation(
        _ prompt: String,
        userTier: SubscriptionTier = .free,
        validationContext: ValidationContext
    ) async throws -> ValidatedResponse {

        let request = LLMRequest(input: prompt, userTier: userTier)
        let llmResponse = try await router.route(request)

        // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º LLMResponse –≤ AIResponse –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        let aiResponse = try parseAIResponse(from: llmResponse.content)

        // –í–∞–ª–∏–¥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        let validated = try await responseValidator.validateAndImprove(
            response: aiResponse,
            context: validationContext
        )

        return validated
    }

    /// –ü–∞—Ä—Å–∏–Ω–≥ LLM –æ—Ç–≤–µ—Ç–∞ –≤ AIResponse
    private func parseAIResponse(from content: String) throws -> AIResponse {
        // –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON
        guard let jsonData = content.data(using: .utf8) else {
            throw NSError(domain: "MultiProviderClient", code: -3,
                         userInfo: [NSLocalizedDescriptionKey: "Failed to encode response"])
        }

        do {
            let decoded = try JSONDecoder().decode(AIResponseJSON.self, from: jsonData)

            return AIResponse(
                action: decoded.action,
                extractedData: decoded.extracted_data ?? [:],
                confidence: decoded.confidence ?? 0.8,
                metadata: [:]
            )
        } catch {
            // Fallback: –µ—Å–ª–∏ –Ω–µ JSON, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π AIResponse
            return AIResponse(
                action: nil,
                extractedData: ["raw_content": content],
                confidence: 0.5,
                metadata: ["parse_error": error.localizedDescription]
            )
        }
    }

    struct AIResponseJSON: Decodable {
        let action: String?
        let extracted_data: [String: Any]?
        let confidence: Double?

        private enum CodingKeys: String, CodingKey {
            case action
            case extracted_data
            case confidence
        }

        init(from decoder: Decoder) throws {
            let container = try decoder.container(keyedBy: CodingKeys.self)
            action = try container.decodeIfPresent(String.self, forKey: .action)
            confidence = try container.decodeIfPresent(Double.self, forKey: .confidence)

            // –î–µ–∫–æ–¥–∏—Ä—É–µ–º extracted_data –∫–∞–∫ generic dictionary
            if let dataContainer = try? container.nestedContainer(keyedBy: AnyCodingKey.self, forKey: .extracted_data) {
                var data: [String: Any] = [:]
                for key in dataContainer.allKeys {
                    if let value = try? dataContainer.decode(String.self, forKey: key) {
                        data[key.stringValue] = value
                    } else if let value = try? dataContainer.decode(Int.self, forKey: key) {
                        data[key.stringValue] = value
                    } else if let value = try? dataContainer.decode(Double.self, forKey: key) {
                        data[key.stringValue] = value
                    } else if let value = try? dataContainer.decode(Bool.self, forKey: key) {
                        data[key.stringValue] = value
                    }
                }
                extracted_data = data
            } else {
                extracted_data = nil
            }
        }
    }

    struct AnyCodingKey: CodingKey {
        var stringValue: String
        var intValue: Int?

        init?(stringValue: String) {
            self.stringValue = stringValue
            self.intValue = nil
        }

        init?(intValue: Int) {
            self.stringValue = "\(intValue)"
            self.intValue = intValue
        }
    }

    /// –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å —è–≤–Ω–æ–π –º–æ–¥–µ–ª—å—é (bypass routing)
    func generate(
        _ prompt: String,
        model: LLMModel,
        temperature: Double = 0.6,
        maxTokens: Int = 384
    ) async throws -> String {

        guard let (url, apiKey, modelName) = endpoint(for: model) else {
            throw NSError(domain: "MultiProviderClient", code: -1,
                         userInfo: [NSLocalizedDescriptionKey: "Model \(model.rawValue) not configured"])
        }

        let system = "You are Sekretar, a helpful planning assistant. Be concise and actionable."

        let body = ChatRequest(
            model: modelName,
            messages: [
                .init(role: "system", content: system),
                .init(role: "user", content: prompt)
            ],
            temperature: temperature,
            max_tokens: maxTokens,
            stream: false
        )

        let data = try await postJSON(url: url, apiKey: apiKey, body: body)
        let decoded = try JSONDecoder().decode(ChatResponse.self, from: data)

        guard let content = decoded.choices.first?.message?.content, !content.isEmpty else {
            throw NSError(domain: "MultiProviderClient", code: -2,
                         userInfo: [NSLocalizedDescriptionKey: "Empty response from \(model.rawValue)"])
        }

        return content
    }

    // MARK: - JSON Mode with Routing

    /// JSON –≤—ã–∑–æ–≤ —Å smart routing
    func jsonCallWithRouting<T: Decodable>(
        schemaDescription: String,
        userContent: String,
        type: T.Type,
        userTier: SubscriptionTier = .free
    ) async throws -> T {

        // –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π prompt –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        let fullPrompt = "JSON Schema: \(schemaDescription)\nUser Content: \(userContent)"
        let request = LLMRequest(input: fullPrompt, userTier: userTier)

        // Router –≤—ã–±–∏—Ä–∞–µ—Ç –º–æ–¥–µ–ª—å
        let response = try await router.route(request)

        // –ü–∞—Ä—Å–∏–º JSON
        guard let jsonData = response.content.data(using: .utf8) else {
            throw NSError(domain: "MultiProviderClient", code: -3,
                         userInfo: [NSLocalizedDescriptionKey: "Failed to encode response as UTF-8"])
        }

        return try JSONDecoder().decode(T.self, from: jsonData)
    }

    // MARK: - Analytics & Management

    /// –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É router'–∞
    func getRouterStats() -> RouterStats {
        return router.getStats()
    }

    /// –û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à
    func clearCache() async {
        await router.clearCache()
    }

    // MARK: - HTTP Helpers (from RemoteLLMProvider)

    struct ChatMessage: Codable {
        let role: String
        let content: String
    }

    struct ChatRequest: Codable {
        let model: String
        let messages: [ChatMessage]
        let temperature: Double?
        let max_tokens: Int?
        let stream: Bool?
    }

    struct ChatResponse: Decodable {
        struct Choice: Decodable {
            struct Message: Decodable {
                let role: String?
                let content: String?
            }
            let index: Int?
            let message: Message?
        }
        let choices: [Choice]
    }

    private func postJSON<T: Encodable>(url: URL, apiKey: String?, body: T) async throws -> Data {
        var req = URLRequest(url: url)
        req.httpMethod = "POST"
        req.setValue("application/json", forHTTPHeaderField: "Content-Type")
        req.setValue("application/json", forHTTPHeaderField: "Accept")

        if let apiKey, !apiKey.isEmpty {
            req.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        }

        req.httpBody = try JSONEncoder().encode(body)

        try Task.checkCancellation()

        let (data, response) = try await session.data(for: req)

        try Task.checkCancellation()

        guard let http = response as? HTTPURLResponse, 200..<300 ~= http.statusCode else {
            let code = (response as? HTTPURLResponse)?.statusCode ?? -1
            let text = String(data: data, encoding: .utf8) ?? ""

            let friendly: String
            switch code {
            case 401, 403:
                friendly = "–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á."
            case 429:
                friendly = "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: –ø–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ."
            default:
                friendly = "–£–¥–∞–ª—ë–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ (\(code))."
            }

            throw NSError(domain: "MultiProviderClient", code: code,
                         userInfo: [NSLocalizedDescriptionKey: friendly + "\n" + text])
        }

        return data
    }
}

// MARK: - LLMProviderProtocol Adapter
/// –ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º LLMProviderProtocol
extension MultiProviderLLMClient: LLMProviderProtocol {

    func generateResponse(_ prompt: String) async throws -> String {
        return try await generateWithRouting(prompt, userTier: .free)
    }

    func detectIntent(_ input: String) async throws -> UserIntent {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º RemoteLLMProvider –¥–ª—è intent detection
        return try await RemoteLLMProvider.shared.detectIntent(input)
    }

    func analyzeTask(_ taskDescription: String) async throws -> TaskAnalysis {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º RemoteLLMProvider –¥–ª—è task analysis
        return try await RemoteLLMProvider.shared.analyzeTask(taskDescription)
    }

    func generateSmartSuggestions(_ context: String) async throws -> [SmartSuggestion] {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º RemoteLLMProvider –¥–ª—è suggestions
        return try await RemoteLLMProvider.shared.generateSmartSuggestions(context)
    }

    func optimizeSchedule(_ tasks: [TaskSummary]) async throws -> ScheduleOptimization {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º RemoteLLMProvider –¥–ª—è schedule optimization
        return try await RemoteLLMProvider.shared.optimizeSchedule(tasks)
    }

    func parseEvent(_ description: String) async throws -> EventDraft {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º RemoteLLMProvider –¥–ª—è event parsing
        return try await RemoteLLMProvider.shared.parseEvent(description)
    }
}
